{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d2dd22f732d24b94bb1e24837ff64bac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ba3a4cba10374ee79c64926c23f6bfb6",
              "IPY_MODEL_c74d8c50d63440a2b910a4217ab16351",
              "IPY_MODEL_0dd4e42399ef495a90ed6d6b5535f4e6"
            ],
            "layout": "IPY_MODEL_e406742d41d94bb381771e563efec81e"
          }
        },
        "ba3a4cba10374ee79c64926c23f6bfb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_28285d093e804ee789c128246306bb15",
            "placeholder": "​",
            "style": "IPY_MODEL_390919ebf003496c961987b3a1e23747",
            "value": "wapo/v2 documents: 100%"
          }
        },
        "c74d8c50d63440a2b910a4217ab16351": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0fb07b36f7f4a1eae8b1fa85554427a",
            "max": 595037,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d282b68393d444729829cf9352486bb2",
            "value": 595037
          }
        },
        "0dd4e42399ef495a90ed6d6b5535f4e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b58e74248b984595825fd03b821c4ad6",
            "placeholder": "​",
            "style": "IPY_MODEL_390dca73f4a945c983a9f4ca5de68f0a",
            "value": " 595037/595037 [07:31&lt;00:00, 971.52it/s]"
          }
        },
        "e406742d41d94bb381771e563efec81e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28285d093e804ee789c128246306bb15": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "390919ebf003496c961987b3a1e23747": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a0fb07b36f7f4a1eae8b1fa85554427a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d282b68393d444729829cf9352486bb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b58e74248b984595825fd03b821c4ad6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "390dca73f4a945c983a9f4ca5de68f0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Installations and getting the dataset in place"
      ],
      "metadata": {
        "id": "f9zs3Y4tjvll"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-terrier &> /dev/null\n",
        "!pip install ir_datasets &> /dev/null"
      ],
      "metadata": {
        "id": "QsT0tl9i8uif"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vNAb49VKTWdy",
        "outputId": "0cec5343-dd9a-4a7a-d55c-978ebd88beea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /root/.ir_datasets\n",
        "!mkdir /root/.ir_datasets/wapo\n",
        "!cp /content/drive/MyDrive/WashingtonPost.v2.tar.gz /root/.ir_datasets/wapo\n",
        "!ls ../root/.ir_datasets/wapo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vd535rp4Te3_",
        "outputId": "71b30efb-5366-4dc1-8c24-a82b77fc7edc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WashingtonPost.v2.tar.gz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ir_datasets\n",
        "import pandas as pd\n",
        "from google.colab import files\n",
        "import os\n",
        "import pyterrier as pt\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "metadata": {
        "id": "zHMHRlEkhsJQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Document class"
      ],
      "metadata": {
        "id": "8rlf1TIqj16i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Borrowed from https://github.com/bwanglzu/Maximal-Marginal-Relevance\n",
        "# and adapted to fit our data and needs \n",
        "\n",
        "\"\"\"Document class, read document, clean document, get terms.\"\"\"\n",
        "import string\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from collections import Counter\n",
        "\n",
        "class Document(object):\n",
        "\n",
        "    def __init__(self, docno):\n",
        "        self.docno = docno # Actual string of the docid such as 'f233ecdeb87a44a6aa9ac429999d2d4c'\n",
        "        # self._name = docno.split('/')[-1]\n",
        "        self._term = None\n",
        "        self._author = None\n",
        "        self._kicker = None\n",
        "        self._title = None\n",
        "\n",
        "    def read(self):\n",
        "        \"\"\"Get terms within documents.\"\"\"\n",
        "        try:\n",
        "\n",
        "          docstore = dataset.docs_store()\n",
        "          self._term = docstore.get(self.docno).body#\n",
        "          self._author=docstore.get(self.docno).author\n",
        "          self._kicker=docstore.get(self.docno).kicker\n",
        "          self._title=docstore.get(self.docno).title\n",
        "        \n",
        "          return self\n",
        "          \n",
        "        except EnvironmentError:\n",
        "            raise IOError(\"Docno not found\")\n",
        "\n",
        "    def lower(self):\n",
        "        \"\"\"Terms to lower case.\"\"\"\n",
        "        self._term = self._term.lower()\n",
        "        return self\n",
        "\n",
        "    def del_punc(self):\n",
        "        \"\"\"Remove punc.\"\"\"\n",
        "        self._term = self._term.translate({k:None for k in string.punctuation})\n",
        "        return self\n",
        "\n",
        "    def del_space_stop(self):\n",
        "        \"\"\"Remove spaces, stopwords.\"\"\"\n",
        "        cached = stopwords.words(\"english\")\n",
        "        self._term = ' '.join([word for word in self._term.split() if word not in cached])\n",
        "        return self\n",
        "\n",
        "    @property\n",
        "    def terms(self):\n",
        "        \"\"\"Finish process\"\"\"\n",
        "        self.read().lower().del_punc().del_space_stop()\n",
        "        return self._term\n",
        "\n",
        "    @property \n",
        "    def name(self):\n",
        "        \"\"\"doc name\"\"\"\n",
        "        return self._name\n",
        "\n",
        "    @property\n",
        "    def author(self):\n",
        "      \n",
        "      if self.read()._author.isalnum():\n",
        "        return self._author\n",
        "      else: \n",
        "        return ''.join([char for char in self._author if char.isalnum()])\n",
        "      \n",
        "      \n",
        "    @property\n",
        "    def kicker(self):\n",
        "      if self.read()._kicker.isalnum():\n",
        "        return self._kicker\n",
        "      else: \n",
        "        return ''.join([char for char in self._kicker if char.isalnum()])\n",
        "\n",
        "    @property\n",
        "    def title(self):\n",
        "        \"\"\"Finish title process\"\"\"\n",
        "        self.read().lower().del_punc().del_space_stop()\n",
        "        return self._title"
      ],
      "metadata": {
        "id": "zYVgFy7U8djF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62ebead9-8540-486e-8cba-1928e2d1be2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reranking definition"
      ],
      "metadata": {
        "id": "TAZuHPdxj6oo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Skeleton borrowed from https://github.com/bwanglzu/Maximal-Marginal-Relevance\n",
        "# drastically adapted to fit our needs and the mmr function is changed to an adaptation of https://medium.com/tech-that-works/maximal-marginal-relevance-to-rerank-results-in-unsupervised-keyphrase-extraction-22d95015c7c5\n",
        "\n",
        "import glob\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "\n",
        "def _build_sim_matrix(initial_ranking=None, alpha=0.5, beta=0.5):\n",
        "  \"\"\"\n",
        "  Build similarity matrix.\n",
        "  Alpha determines ratio of tfidf repr vs binary (higher alpha is more emphasis on binary representation)\n",
        "  Beta determines ratio of title vs body (higher beta is more emphasis on title)\n",
        "\n",
        "  \"\"\"\n",
        "  terms = []\n",
        "  titles = []\n",
        "  a_k = []\n",
        "  docs = initial_ranking['docno'].tolist()\n",
        "  for d in docs:\n",
        "    d = Document(d)\n",
        "    terms.append(d.terms)\n",
        "    a_k.append(d.author + \" \" +  d.kicker)\n",
        "    titles.append(d.title)\n",
        "    comb = d.author + \" \" +  d.kicker\n",
        "\n",
        "  tfidf = TfidfVectorizer().fit_transform(terms)\n",
        "  tfidf_title = TfidfVectorizer().fit_transform(titles)\n",
        "\n",
        "  counts = CountVectorizer().fit_transform(a_k)\n",
        "  pairwise_counts = ((counts*counts.T).A)/2\n",
        "  \n",
        "\n",
        "  pairwise_similarity_body = (tfidf * tfidf.T).A\n",
        "  pairwise_similarity_title = (tfidf_title * tfidf_title.T).A\n",
        "\n",
        "  pairwise_similarity=(beta*pairwise_similarity_body + (1-beta)*pairwise_similarity_title)\n",
        "  \n",
        "  combined = (alpha*pairwise_counts + (1-alpha)*pairwise_similarity)\n",
        "  return pd.DataFrame(combined)\n",
        "  \n",
        "def _lookup_rel(initial_ranking, doc):\n",
        "\t\"\"\"Lookup table for relevance.\"\"\"\n",
        "\treturn initial_ranking.loc[initial_ranking['docno'] == doc, 'score'].iloc[0]\n",
        "\n",
        "def _lookup_sim(doc1, doc2, sim_matrix, initial_ranking):\n",
        "\t\"\"\"Lookup pairwise similarity.\"\"\"\n",
        "\ttry:\n",
        "\t    doc1_idx = initial_ranking.index[initial_ranking['docno'] == doc1].tolist()[0]\n",
        "\t    doc2_idx = initial_ranking.index[initial_ranking['docno'] == doc2].tolist()[0]\n",
        "\t\t\t\n",
        "\texcept IndexError:\n",
        "\t\treturn 0\n",
        "\tsim_doc1_doc2 = sim_matrix.iat[doc1_idx, doc2_idx]\n",
        "\treturn sim_doc1_doc2\n",
        "\n",
        "\n",
        "def rank(initial_ranking, lambda_score, query, alpha = 0.5, beta = 0.5):\n",
        "\t\"\"\"Ranking based on mmr score.\"\"\"\n",
        "\n",
        "\tsim_matrix = _build_sim_matrix(initial_ranking=initial_ranking, alpha=alpha, beta=beta)\n",
        "\treturn maximal_marginal_relevance(initial_ranking=initial_ranking, sim_matrix=sim_matrix, query=query, lambda_constant=lambda_score)\n",
        " "
      ],
      "metadata": {
        "id": "jO2bdu1W8lIO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def maximal_marginal_relevance(initial_ranking, sim_matrix, query, lambda_constant=0.5):\n",
        "    \"\"\"\n",
        "    Documentation here.\n",
        "    \"\"\"\n",
        "\n",
        "    s = [] # reranking\n",
        "    r = initial_ranking['docno'].to_list()\n",
        "\n",
        "    while len(r) > 0:\n",
        "        score = None\n",
        "        # phrase_to_add = ''\n",
        "        for i in r:\n",
        "            first_part = _lookup_rel(initial_ranking, i)  \n",
        "            second_part = 0\n",
        "            for j in s:\n",
        "                cos_sim = _lookup_sim(i, j['docno'], sim_matrix=sim_matrix, initial_ranking=initial_ranking) \n",
        "\n",
        "                if cos_sim > second_part:\n",
        "                    second_part = cos_sim\n",
        "            equation_score = lambda_constant*(first_part)-(1-lambda_constant) * second_part\n",
        "\n",
        "            if score == None:\n",
        "                score = equation_score\n",
        "                doc_to_add = i\n",
        "            elif equation_score > score:\n",
        "                score = equation_score\n",
        "                doc_to_add = i\n",
        "        r.remove(doc_to_add)\n",
        "        s.append({'docno': doc_to_add, 'score': score, 'query': query})\n",
        "    return s \n",
        "\n"
      ],
      "metadata": {
        "id": "PpWIRM6n4Dd_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initial Indexing + Ranking "
      ],
      "metadata": {
        "id": "1r04Ok2uj-7g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = ir_datasets.load(\"wapo/v2/trec-core-2018\")\n",
        "print(dataset)\n",
        "print(dataset.docs_count())"
      ],
      "metadata": {
        "id": "RDavjgHD0-LU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4cd4f72-34e4-4181-ae50-242366bd1d69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset(id='wapo/v2/trec-core-2018', provides=['docs', 'queries', 'qrels'])\n",
            "595037\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Show the first 10 documents:"
      ],
      "metadata": {
        "id": "Oj5bV_IKRE2E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pt.init()\n",
        "dataset_pt = pt.get_dataset('irds:wapo/v2')\n",
        "# Index wapo/v2\n",
        "indexer = pt.IterDictIndexer('./indices/wapo_v2', meta={\"docno\": 36})\n",
        "try: \n",
        "  index_ref = indexer.index(dataset_pt.get_corpus_iter(), fields=['url', 'title', 'author', 'kicker', 'body'])\n",
        "\n",
        "except Exception as e:\n",
        "  index_ref = './indices/wapo_v2/data.properties'\n",
        "  print('Warning: Exception was caught: \\n', e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231,
          "referenced_widgets": [
            "d2dd22f732d24b94bb1e24837ff64bac",
            "ba3a4cba10374ee79c64926c23f6bfb6",
            "c74d8c50d63440a2b910a4217ab16351",
            "0dd4e42399ef495a90ed6d6b5535f4e6",
            "e406742d41d94bb381771e563efec81e",
            "28285d093e804ee789c128246306bb15",
            "390919ebf003496c961987b3a1e23747",
            "a0fb07b36f7f4a1eae8b1fa85554427a",
            "d282b68393d444729829cf9352486bb2",
            "b58e74248b984595825fd03b821c4ad6",
            "390dca73f4a945c983a9f4ca5de68f0a"
          ]
        },
        "id": "g9jNcLj6hpHL",
        "outputId": "87175d18-a9d2-453e-852a-63e35793430d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "terrier-assemblies 5.7 jar-with-dependencies not found, downloading to /root/.pyterrier...\n",
            "Done\n",
            "terrier-python-helper 0.0.7 jar not found, downloading to /root/.pyterrier...\n",
            "Done\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "PyTerrier 0.9.1 has loaded Terrier 5.7 (built by craigm on 2022-11-10 18:30) and terrier-helper 0.0.7\n",
            "\n",
            "[INFO] [starting] building docstore\n",
            "docs_iter: 595037doc [11:48, 840.35doc/s]\n",
            "[INFO] [finished] docs_iter: [11:48] [595037doc] [840.34doc/s]\n",
            "[INFO] [finished] building docstore [11:48]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "wapo/v2 documents:   0%|          | 0/595037 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d2dd22f732d24b94bb1e24837ff64bac"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load the index, print the statistics\n",
        "index = pt.IndexFactory.of(index_ref)\n",
        "print(index.getCollectionStatistics().toString())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6kSAYksQllLW",
        "outputId": "7fbaf71b-7e3c-4641-9d9a-b6a523845409"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of documents: 595037\n",
            "Number of terms: 674473\n",
            "Number of postings: 111041554\n",
            "Number of fields: 5\n",
            "Number of tokens: 177895814\n",
            "Field names: [url, title, author, kicker, body]\n",
            "Positions:   false\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_pt = pt.get_dataset('irds:wapo/v2/trec-core-2018')\n",
        "pipeline = pt.BatchRetrieve(index_ref, wmodel='BM25')\n",
        "ranking = pipeline(dataset_pt.get_topics('title'))"
      ],
      "metadata": {
        "id": "uU_0z4Vbd3c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99a6ebfd-8152-4e61-d2e1-d8ed5db4dbd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[INFO] [starting] https://trec.nist.gov/data/core/topics2018.txt\n",
            "[INFO] [finished] https://trec.nist.gov/data/core/topics2018.txt: [00:00] [24.1kB] [10.2MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reranking\n",
        "\n",
        "Checking for preprocessing:"
      ],
      "metadata": {
        "id": "kBYKg2rxjXMk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "\n",
        "for x in ['author', 'title', 'kicker', 'body']:\n",
        "  print(x)\n",
        "  print('isnan: ', sum(pd.DataFrame(dataset.docs_iter()[:10000])[x].isna()))\n",
        "  print('empty str: ', sum(pd.DataFrame(dataset.docs_iter()[:10000])[x]==''))\n"
      ],
      "metadata": {
        "id": "ipEctK0au4Kx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9c92f4c-bd0c-4c1f-8699-d79155559f2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "author\n",
            "isnan:  0\n",
            "empty str:  2268\n",
            "title\n",
            "isnan:  410\n",
            "empty str:  0\n",
            "kicker\n",
            "isnan:  0\n",
            "empty str:  87\n",
            "body\n",
            "isnan:  0\n",
            "empty str:  49\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_relevance(docno, query_id, qrels):\n",
        "  \n",
        "    try:\n",
        "      doc_given_query = qrels[(qrels['query_id'] == query_id) & \n",
        "                              (qrels['doc_id'] == docno)]\n",
        "      return int(doc_given_query['relevance'])\n",
        "    except:\n",
        "      return None \n",
        "\n",
        "\n",
        "def rerank(lambda_score, alpha, beta):\n",
        "  rerank_result = []\n",
        "  for q in np.unique(ranking['query']):\n",
        "    q_rank = ranking[ranking['query'] == q] # kick out kickerless (these are empty strings) and relevance-less here for latter use get relevance function \n",
        "    query_id = np.unique(q_rank['qid'])[0]\n",
        "    missing_data = [d for d in q_rank['docno'] if (get_relevance(d, query_id, qrels)==None or Document(d).kicker == '' or Document(d).title==None)] # for one of them there are only 62 left, title is never a problem here\n",
        "    q_rank = q_rank.drop(q_rank[q_rank['docno'].isin(missing_data)].index)\n",
        "    max_score =np.max(q_rank['score'])\n",
        "\n",
        "    q_rank['score'] = q_rank['score']/max_score\n",
        "    q_rank.reset_index(inplace=True)\n",
        "\n",
        "    rerank_result+=rank(initial_ranking = q_rank[:50], lambda_score = lambda_score, query = q, alpha = alpha, beta = beta)\n",
        "    \n",
        "  return rerank_result"
      ],
      "metadata": {
        "id": "Z1YHMhLljgN7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # getting the rerankings\n",
        "\n",
        "# qrels = pd.DataFrame(dataset.qrels_iter())\n",
        "\n",
        "# alpha_schedule = [0, 0.25, 0.5, 0.75, 1]\n",
        "# beta_schedule = [0, 0.25, 0.5, 0.75, 1]\n",
        "# lmbd = 0.25                    #[0.25, 0.5, 0.75]\n",
        "\n",
        "# for alpha in alpha_schedule:\n",
        "#   for beta in beta_schedule:\n",
        "#     pd.DataFrame(rerank(lmbd, alpha, beta)).to_csv(f'/content/drive/MyDrive/RU/IR/lambda={lmbd}_alpha={alpha}_beta={beta}.csv')"
      ],
      "metadata": {
        "id": "vvHlvqARjEQD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation functions"
      ],
      "metadata": {
        "id": "XSvBH-gvkeDz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Utils"
      ],
      "metadata": {
        "id": "0ohX0HLa_WgR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os \n",
        "\n",
        "\n",
        "def read_all_frames(dir): \n",
        "  data = {}\n",
        "  for filename in os.listdir(dir):\n",
        "      if filename.endswith(\"csv\"):  \n",
        "          print(filename)\n",
        "          p = os.path.join(dir, filename)\n",
        "          data[filename[:-4]]= pd.read_csv(p)\n",
        "  return data\n",
        "\n",
        "\n",
        "def query_helper(string):\n",
        "  '''\n",
        "  preprocessing necessary to find qid\n",
        "  '''\n",
        "  string = string.replace('u.s.', 'u s')\n",
        "  string = ''.join([char for char in string if char.isalnum() or char == ' ' or char == '-'])\n",
        "  string = ''.join([' ' if char == '-' else char for char in string ])\n",
        "  return string\n",
        "\n",
        "\n",
        "\n",
        "def lookup_qid(query, df):\n",
        "  '''\n",
        "  takes query title, preprocessed or not \n",
        "  takes pd.DataFrame(dataset.queries_iter()) as df \n",
        "  '''\n",
        "\n",
        "  try:\n",
        "    return df[df['title'] == query]['query_id'].iloc[0]\n",
        "  except IndexError:\n",
        "    df[\"title\"] = df[\"title\"].str.lower().apply(query_helper)\n",
        "    return df[df['title'] == query]['query_id'].iloc[0]\n",
        "\n",
        "\n",
        "all_frames = read_all_frames('/content/drive/MyDrive/RU/IR') \n",
        "df = pd.DataFrame(dataset.queries_iter())\n",
        "qrels = pd.DataFrame(dataset.qrels_iter())\n"
      ],
      "metadata": {
        "id": "PUupOWGa_zXf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Eval funcs"
      ],
      "metadata": {
        "id": "qCxrmu-dBXwt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def topic_recall(ranking, query, queries_iter_df, qrels, k=10):\n",
        "  \"\"\"\n",
        "  Ranking: a ranking containing different queries \n",
        "  Query: For which query to \n",
        "  queries_iter_df: Dataframe which contains both, queries (title) and query_id (preferably already formatted in the way it is also in the ranking)\n",
        "  qrels: query-relevance dataframe\n",
        "  k: for which k to get the recall\n",
        "  Returns ratio of (unique topics covered)/(all unique relevant topics)\n",
        "  \"\"\"\n",
        "  q_rank = ranking[ranking['query'] == query].reset_index()[:k]\n",
        "  qid = lookup_qid(query=query, df=queries_iter_df)\n",
        "\n",
        "  TP_topics = set()\n",
        "\n",
        "  qrels = qrels[qrels['query_id'] == qid].reset_index()\n",
        "  for doc in q_rank['docno']:\n",
        "\n",
        "    doc_relevance = get_relevance(docno=doc, query_id=qid, qrels=qrels)\n",
        "    if doc_relevance != None and doc_relevance > 0:\n",
        "        TP_topics.add(Document(doc).kicker)\n",
        "\n",
        "  actually_rel = qrels[qrels['relevance'] > 0]\n",
        "\n",
        "  unique_rel_topics = np.unique([Document(d).kicker for d in actually_rel['doc_id']])\n",
        "  if unique_rel_topics > k:\n",
        "    FN = k-len(TP_topics)\n",
        "  else:\n",
        "    FN = len(unique_rel_topics)-len(TP_topics)\n",
        "\n",
        "  TP = len(TP_topics)\n",
        "  return TP/(TP+FN)\n"
      ],
      "metadata": {
        "id": "7OvAq13p_isJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import combinations \n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.metrics import jaccard_score\n",
        "\n",
        "def avg_dissim(reranked, k): \n",
        "  \"\"\"\n",
        "  takes reranked list as returned by MMR class \n",
        "  returns average similarity of pairs of top k docuements in ranking \n",
        "  uses tf-idf representation and cosine similarity\n",
        "  \"\"\"\n",
        "  reranked = reranked[:k]\n",
        "  if type(reranked) is list:\n",
        "    perm = combinations(reranked, 2)\n",
        "  else: \n",
        "    perm = combinations(reranked['docno'], 2)\n",
        "\n",
        "  result = []\n",
        "  terms = []\n",
        "\n",
        "  for pair in list(perm): \n",
        "    if type(reranked) is list:\n",
        "      doc1 = pair[0]['docno']\n",
        "      doc2 = pair[1]['docno']\n",
        "    else: \n",
        "      doc1 = pair[0]\n",
        "      doc2 = pair[1]\n",
        "\n",
        "    terms.append(Document(doc1).terms)\n",
        "    terms.append(Document(doc2).terms)\n",
        "    tfidf = TfidfVectorizer().fit_transform(terms)\n",
        "\n",
        "    sim = cosine_similarity(tfidf[0], tfidf[1])\n",
        "    result.append(1-sim.squeeze())\n",
        "\n",
        "  return np.mean(result)"
      ],
      "metadata": {
        "id": "375k_tX5R58g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "\n",
        "\n",
        "def g(relevance, tau): \n",
        "    \"\"\"\n",
        "    utility function g to compute probability of relevance given a document and a query \n",
        "    takes relevance and cosntant tau \n",
        "    return g factor \n",
        "    (tau may be 0 given that we only have max(r)=2)\n",
        "    \"\"\"\n",
        "    res = relevance - tau\n",
        "    if res <0:\n",
        "        return 0 \n",
        "    else:\n",
        "        return res \n",
        "\n",
        "\n",
        "def p_rel(g, g_max): \n",
        "    \"\"\"\n",
        "    returns \n",
        "    \"\"\"\n",
        "    return (2**g-1)/2**g_max\n",
        "\n",
        "def disc(l, k): \n",
        "    if l<k: \n",
        "        return 1 \n",
        "    else: \n",
        "        return l-k\n",
        "\n",
        "def distance(doc1, doc2): \n",
        "    \"\"\" \n",
        "    Takes two doc_no\n",
        "    Returns cosine dissimilarity \n",
        "    \"\"\"\n",
        "    terms = []\n",
        "    terms.append(Document(doc1).terms)\n",
        "    terms.append(Document(doc2).terms)\n",
        "    try:\n",
        "      tfidf = TfidfVectorizer().fit_transform(terms)\n",
        "      sim = cosine_similarity(tfidf[0], tfidf[1])\n",
        "    except: \n",
        "      return 0 \n",
        "\n",
        "    return 1-sim.squeeze()\n",
        "    \n",
        "\n",
        "\n",
        "def ILD(reranked_list, document:str, query_id:str, qrels, k): \n",
        "    \"\"\"\n",
        "    takes \n",
        "        reranked list with respect to one query, \n",
        "        document number (doc_no), \n",
        "        query_d\n",
        "    dataframe with queries, relevance and docno has to exist \n",
        "    \"\"\"\n",
        "    reranked_list = reranked_list[:k]\n",
        "  \n",
        "    pos_doc_k = reranked_list.index[reranked_list['docno']==document].tolist()[0]\n",
        "  \n",
        "\n",
        "    if 'qrels' not in globals():\n",
        "        qrels = pd.DataFrame(dataset.qrels_iter())\n",
        "\n",
        "    g_max = np.max(qrels['relevance'][qrels['query_id'] ==query_id])\n",
        "\n",
        "    numerator=0\n",
        "    C_k = 0 \n",
        "\n",
        "    for l, doc_l in enumerate(reranked_list['docno']): \n",
        "        \n",
        "        discount = disc(l, pos_doc_k)\n",
        "        rel_l = get_relevance(query_id=query_id, docno= doc_l, qrels=qrels) # this was in a try and except before we removed all the ones without relevance\n",
        "        g_score_l = g(rel_l, 0)\n",
        "        p_rel_l = p_rel(g_score_l, g_max=g_max)\n",
        "        dist = distance(document, doc_l)\n",
        "        numerator += discount*p_rel_l*dist\n",
        "\n",
        "        if doc_l != document:\n",
        "            C_k += discount*p_rel_l\n",
        "\n",
        "    if C_k == 0:\n",
        "      return None # this is the case if there is only one or zero relevant docs\n",
        "    else:\n",
        "      return numerator/C_k\n",
        "  \n",
        "def avg_ILD(ranking, query_id:str, qrels, k):\n",
        "  \"\"\"\n",
        "  returns average ILD of first k items in ranking \n",
        "  omits the value for the only relevant doc if only one is relevant \n",
        "  returns zero if no relvant docs are in ranking \n",
        "  \"\"\"\n",
        "\n",
        "  res = 0\n",
        "  n_docs = k\n",
        "\n",
        "  for doc in ranking['docno'][:k]:\n",
        "    div = ILD(ranking, doc, query_id, qrels, k)\n",
        "    if div != None:\n",
        "      res += div\n",
        "    else: \n",
        "      n_docs -= 1 # if there is only one relevant doc\n",
        "  if n_docs ==0:\n",
        "    return 0 # this happens if there are zero relevant docs\n",
        "  else:\n",
        "    return res/n_docs\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    "
      ],
      "metadata": {
        "id": "sVycaKgL2dpG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qrels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "rpRf8Y2yYsCO",
        "outputId": "7aa4bef3-b218-4643-df57-86f8c9d0602e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      query_id                                doc_id  relevance iteration\n",
              "0          321      004c6120d0aa69da29cc045da0562168          0         0\n",
              "1          321      005a1f0c2064487a7f15443b2a5f349a          0         0\n",
              "2          321  00722094-2935-11e2-b4e0-346287b7e56c          0         0\n",
              "3          321  007d2856-7cc4-11e4-84d4-7c896b90abdc          0         0\n",
              "4          321  009aafb6-0283-11e6-8bb1-f124a43f84dc          0         0\n",
              "...        ...                                   ...        ...       ...\n",
              "26228      825  fd63b1f8-f00e-11e4-a55f-38924fca94f9          0         0\n",
              "26229      825  fdeefde0-44e1-11e4-b47c-f5889e061e5f          0         0\n",
              "26230      825      fe320ce7929e640c70458009f73e5241          0         0\n",
              "26231      825      ff1c523ea149f03d89019adb8782cdd9          0         0\n",
              "26232      825  ff3a25b0-0ba4-11e4-8341-b8072b1e7348          0         0\n",
              "\n",
              "[26233 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2db034d1-8362-4074-a8aa-6b9b8c38e456\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>query_id</th>\n",
              "      <th>doc_id</th>\n",
              "      <th>relevance</th>\n",
              "      <th>iteration</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>321</td>\n",
              "      <td>004c6120d0aa69da29cc045da0562168</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>321</td>\n",
              "      <td>005a1f0c2064487a7f15443b2a5f349a</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>321</td>\n",
              "      <td>00722094-2935-11e2-b4e0-346287b7e56c</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>321</td>\n",
              "      <td>007d2856-7cc4-11e4-84d4-7c896b90abdc</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>321</td>\n",
              "      <td>009aafb6-0283-11e6-8bb1-f124a43f84dc</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26228</th>\n",
              "      <td>825</td>\n",
              "      <td>fd63b1f8-f00e-11e4-a55f-38924fca94f9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26229</th>\n",
              "      <td>825</td>\n",
              "      <td>fdeefde0-44e1-11e4-b47c-f5889e061e5f</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26230</th>\n",
              "      <td>825</td>\n",
              "      <td>fe320ce7929e640c70458009f73e5241</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26231</th>\n",
              "      <td>825</td>\n",
              "      <td>ff1c523ea149f03d89019adb8782cdd9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26232</th>\n",
              "      <td>825</td>\n",
              "      <td>ff3a25b0-0ba4-11e4-8341-b8072b1e7348</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>26233 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2db034d1-8362-4074-a8aa-6b9b8c38e456')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2db034d1-8362-4074-a8aa-6b9b8c38e456 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2db034d1-8362-4074-a8aa-6b9b8c38e456');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def precision(ranking, k, q_id):\n",
        "  ranking = ranking[:k]\n",
        "  all_rel = np.sum(qrels[qrels['query_id'] == q_id]['relevance'])\n",
        "  if all_rel <k:\n",
        "    k = all_rel\n",
        "  # get all relevant docs - divide rel by this if it is lower than k\n",
        "  rel =0\n",
        "  for doc in ranking['docno']:\n",
        "    relevance=get_relevance(doc, q_id, qrels)\n",
        "    if relevance >0:\n",
        "      rel += 1\n",
        "  return rel/k\n"
      ],
      "metadata": {
        "id": "DlYCiFkvczfQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Results"
      ],
      "metadata": {
        "id": "WeE3prLujsmW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_queries_qid = pd.DataFrame(dataset.queries_iter())\n",
        "all_queries = np.unique(df_queries_qid['title'])\n",
        "all_queries = pd.Series(all_queries).str.lower().apply(query_helper) # make the queries findable\n",
        "all_frames = read_all_frames('/content/drive/MyDrive/RU/IR')\n",
        "\n",
        "\n",
        "frames={}\n",
        "for name, df in all_frames.items():\n",
        "  if name.startswith('lambda'):\n",
        "    frames[name] = df\n",
        "\n",
        "frames['base_ranking'] = ranking \n",
        "\n",
        "average_results=[]\n",
        "\n",
        "k=10\n",
        "counter=0\n",
        "for name, df in frames.items(): \n",
        "  \n",
        "   final_data = {}\n",
        "   final_data['config'] = name\n",
        "   results = []\n",
        "   for query in all_queries:\n",
        "     r = {}\n",
        "     r['query'] = query\n",
        "     r['name'] = name\n",
        "\n",
        "     q_rank = df[df['query'] == query][:50]\n",
        "     q_id = lookup_qid(query, df_queries_qid)\n",
        "     \n",
        "     if name == 'base_ranking':\n",
        "        missing_data = [d for d in q_rank['docno'] if (get_relevance(d, q_id, qrels)==None or Document(d).kicker == '' or Document(d).title==None)] # for one of them there are only 62 left, title is never a problem here\n",
        "        q_rank = q_rank.drop(q_rank[q_rank['docno'].isin(missing_data)].index).reset_index()\n",
        "\n",
        "     avg_ild = avg_ILD(q_rank, q_id, qrels, 10)\n",
        "     r['avg_ild']= avg_ild\n",
        "\n",
        "     prec = precision(q_rank, k, q_id) \n",
        "     r['precision']= prec\n",
        "\n",
        "     t_recall = topic_recall(q_rank, query, df_queries_qid, qrels=qrels, k=k)\n",
        "     r['t_recall']= t_recall\n",
        "\n",
        "     avg_sim = avg_dissim(q_rank, k=k) \n",
        "     r['avg_sim']= avg_sim\n",
        "\n",
        "\n",
        "     results.append(r)\n",
        "   results_finished = pd.DataFrame(results)\n",
        "   results_finished.to_csv(f'/content/drive/MyDrive/RU/IR/average_results_{name}.csv')\n",
        "\n",
        "   precision_mean = np.mean(results_finished['precision'])\n",
        "   final_data['precision_mean'] = precision_mean\n",
        "   ild = np.mean(results_finished['avg_ild'])\n",
        "   final_data['avg_ild'] = ild\n",
        "   recall_mean = np.mean(results_finished['t_recall'])\n",
        "   final_data['recall_mean'] = recall_mean\n",
        "   avg_diss_mean = np.mean(results_finished['avg_sim'])\n",
        "   final_data['avg_diss_mean'] = avg_diss_mean\n",
        "   average_results.append(final_data)\n",
        " \n",
        "\n",
        "   pd.DataFrame(average_results).to_csv('/content/drive/MyDrive/RU/IR/average_results.csv')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "cY6rlko4gu-y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
